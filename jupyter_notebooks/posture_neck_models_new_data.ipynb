{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc67a0f0-6af8-4946-baf5-a33cd11cae68",
   "metadata": {},
   "source": [
    "# **Neck Posture with video detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739056b5-3210-4421-8810-6a0a562b3274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bed0c7e-5b86-4ddc-8467-90bf0bb2c397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.11/site-packages (from keras) (3.9.0)\n",
      "Collecting optree (from keras)\n",
      "  Using cached optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp311-cp311-macosx_11_0_arm64.whl (283 kB)\n",
      "Installing collected packages: namex, optree, keras\n",
      "Successfully installed keras-3.5.0 namex-0.0.8 optree-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1046ab-1cbf-47a8-ba38-8f90b161f409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.11/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391244cb-fca8-47f7-a2cd-9b79adf15cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.11/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1e7c3b-c5db-4523-a99c-3c7faa903a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.11/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229324f6-b67e-40bf-99a3-841ce6b41251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b851e270-da97-4fab-9bda-cbb741e06293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de96c6d-272e-419f-b6d0-d443ca152480",
   "metadata": {},
   "source": [
    "### Run mediapipe through the pictures to extract the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7af05aa4-16d9-4b11-91b0-2714c544811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723719006.061303 1579939 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1723719006.113073 1580393 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1723719006.118495 1580394 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Paths to dataset folders\n",
    "good_posture_dir = '/Users/gabrielaclementedeoliveira/Documents/GitHub/final_project_ironhak/pics_ml/good_neck_posture'\n",
    "bad_posture_dir = '/Users/gabrielaclementedeoliveira/Documents/GitHub/final_project_ironhak/pics_ml/bad_neck_posture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8e17e9-0e85-4863-950a-79c34e17a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Convert image to RGB for MediaPipe\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Process the image to extract pose landmarks\u001b[39;00m\n\u001b[1;32m     41\u001b[0m result \u001b[38;5;241m=\u001b[39m pose\u001b[38;5;241m.\u001b[39mprocess(image_rgb)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Function to extract key points\n",
    "def extract_keypoints(landmarks):\n",
    "    keypoints = []\n",
    "    for landmark in landmarks.landmark:\n",
    "        keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
    "    return keypoints\n",
    "\n",
    "# Prepare a list to hold the dataset\n",
    "data = []\n",
    "\n",
    "# Process images in the \"good_neck_posture\" folder\n",
    "for img_name in os.listdir(good_posture_dir):\n",
    "    img_path = os.path.join(good_posture_dir, img_name)\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    # Convert image to RGB for MediaPipe\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image to extract pose landmarks\n",
    "    result = pose.process(image_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        # Extract key points\n",
    "        keypoints = extract_keypoints(result.pose_landmarks)\n",
    "        \n",
    "        # Append label (\"good\" = 0)\n",
    "        keypoints.append(0)\n",
    "        \n",
    "        # Add to the dataset list\n",
    "        data.append(keypoints)\n",
    "\n",
    "# Process images in the \"bad_neck_posture\" folder\n",
    "for img_name in os.listdir(bad_posture_dir):\n",
    "    img_path = os.path.join(bad_posture_dir, img_name)\n",
    "    image = cv2.imread(img_path)\n",
    "\n",
    "    # Convert image to RGB for MediaPipe\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image to extract pose landmarks\n",
    "    result = pose.process(image_rgb)\n",
    "\n",
    "    if result.pose_landmarks:\n",
    "        # Extract key points\n",
    "        keypoints = extract_keypoints(result.pose_landmarks)\n",
    "        \n",
    "        # Append label (\"bad\" = 1)\n",
    "        keypoints.append(1)\n",
    "        \n",
    "        # Add to the dataset list\n",
    "        data.append(keypoints)\n",
    "\n",
    "# Convert the dataset list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "#df.to_csv('neck_posture_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048d839-7902-46f2-ad7f-e1275b983a32",
   "metadata": {},
   "source": [
    "### Train the model on the pictures/datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86fd32f-7e29-4f76-a69e-2f8fac25d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce0035-3314-4c28-b108-bca3e7323225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.iloc[:, :-1].values  # All columns except the last one (key points)\n",
    "y = df.iloc[:, -1].values   # The last column (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5de77-5e86-433c-aeb9-59c6db923542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45237e67-7be6-474d-aab3-49e7dcf4cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb5525e-64f4-4631-aa4b-eb8fd07b0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de053a7-8d08-4687-adc7-6f3435d88bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'logisticregression__C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'logisticregression__solver': ['liblinear', 'saga']  # Solver options\n",
    "}\n",
    "\n",
    "# Create a pipeline with scaling and model\n",
    "pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f034f7c5-8633-416d-a61a-bce6bc591823",
   "metadata": {},
   "source": [
    "### Testing another models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd327208-4402-4db9-9d93-aa8cf40ac45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gb_y_pred = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a893ef35-3e4a-4592-8459-0e38bcf08b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bcff78-a7dc-4b3e-8385-b2c2b03a13db",
   "metadata": {},
   "source": [
    "### Ensemble Methods:\n",
    "Combine multiple models using VotingClassifier to potentially improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c077e1-248b-4afb-ac39-90193c9f9fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize base models\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an ensemble of models\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('lr', lr_model), \n",
    "    ('rf', rf_model), \n",
    "    ('gb', gb_model)\n",
    "], voting='soft')\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Ensemble Model Accuracy:\", accuracy_score(y_test, ensemble_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c3494-af5c-4515-9e7d-509ee9d1e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76dd443-67b4-48db-a0a6-d9eccfe8833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Assuming you've already trained your ensemble model and made predictions\n",
    "ensemble_y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, ensemble_y_pred)\n",
    "print(\"Ensemble Model Accuracy:\", accuracy)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, ensemble_y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Good', 'Bad'], yticklabels=['Good', 'Bad'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Ensemble Model')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, ensemble_y_pred, target_names=['Good', 'Bad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9303ace-d022-46fe-9871-2f249aebc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Make predictions with the best model found by GridSearchCV\n",
    "grid_y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, grid_y_pred)\n",
    "print(f\"GridSearchCV Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test, grid_y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Good', 'Bad'], yticklabels=['Good', 'Bad'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for GridSearchCV Model')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, grid_y_pred, target_names=['Good', 'Bad']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c50d5-c633-47c1-8f94-6abdefe2147c",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21155f4-e24a-4500-8d9f-19df712919ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained ensemble model\n",
    "#joblib.dump(ensemble_model, 'ensemble_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e620e-2fff-453b-bbff-729126e8b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "loaded_model = joblib.load('ensemble_model.pkl')\n",
    "\n",
    "# Make predictions with the loaded model\n",
    "loaded_y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Loaded Model Accuracy:\", accuracy_score(y_test, loaded_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2289215-743b-4e6e-b581-e6ac436fc34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model from GridSearchCV\n",
    "#joblib.dump(grid_search.best_estimator_, 'best_logistic_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffd750-69bc-4738-844b-e20a611ca858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load('best_logistic_model.pkl')\n",
    "\n",
    "# Use the model to make predictions\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1383536-f349-4642-af2c-c612779c8592",
   "metadata": {},
   "source": [
    "## Video recognition of the neck posture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f46c4c-bd17-441e-9e07-624e9831e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained ensemble model\n",
    "model = joblib.load('best_logistic_model.pkl')\n",
    "\n",
    "# Initialize MediaPipe for pose detection\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Define function to extract key points\n",
    "def extract_keypoints(landmarks):\n",
    "    keypoints = []\n",
    "    for landmark in landmarks.landmark:\n",
    "        keypoints.extend([landmark.x, landmark.y, landmark.z])\n",
    "    return keypoints\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert image to RGB\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the image\n",
    "    result = pose.process(image_rgb)\n",
    "    \n",
    "    if result.pose_landmarks:\n",
    "        # Extract key points\n",
    "        keypoints = extract_keypoints(result.pose_landmarks)\n",
    "        \n",
    "        # Prepare keypoints for prediction\n",
    "        keypoints_array = np.array(keypoints).reshape(1, -1)\n",
    "        \n",
    "        # Predict posture\n",
    "        prediction = model.predict(keypoints_array)\n",
    "        \n",
    "        # Display result and alert\n",
    "        if prediction[0] == 1:\n",
    "            cv2.putText(frame, \"Bad Posture Alert!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Good Posture\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Posture Detection', frame)\n",
    "    \n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81113cd-003b-4835-a182-b84064812d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf0e9c-8faf-4412-b4c3-f0809909d6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
